{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikidata: The state of the art (CHARTS)\n",
    "\n",
    "This notebook consolidates all Wikidata processing for the charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install SPARQLWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import hashlib\n",
    "import urllib.request\n",
    "from collections import Counter, defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from datetime import datetime\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "CACHE_DIR = \"wikidata_cache\"\n",
    "VIS_DIR = \"vis/\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "os.makedirs(VIS_DIR, exist_ok=True)\n",
    "\n",
    "ENDPOINT_URL = \"https://query.wikidata.org/sparql\"\n",
    "USER_AGENT = \"Wikidata: State of the Art; Marian DÃ¶rk\"\n",
    "ENTITY_URL_TEMPLATE = \"https://www.wikidata.org/wiki/Special:EntityData/{}.json\"\n",
    "\n",
    "# Rate limiting\n",
    "CURRENT_DELAY = 0.1\n",
    "MIN_DELAY = 0.1\n",
    "MAX_DELAY = 60.0\n",
    "\n",
    "# Parallel fetching\n",
    "MAX_WORKERS = 10  # Concurrent HTTP requests\n",
    "\n",
    "def timestamp():\n",
    "    return datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "def format_time_remaining(seconds):\n",
    "    if seconds < 60:\n",
    "        return f\"{seconds:.0f}s\"\n",
    "    elif seconds < 3600:\n",
    "        return f\"{seconds / 60:.0f}m\"\n",
    "    else:\n",
    "        hours = int(seconds // 3600)\n",
    "        minutes = int((seconds % 3600) // 60)\n",
    "        return f\"{hours}h {minutes}m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SPARQL UTILITIES\n",
    "# =============================================================================\n",
    "\n",
    "def query_hash(query_template: str) -> str:\n",
    "    h = hashlib.sha1()\n",
    "    h.update(query_template.encode(\"utf-8\"))\n",
    "    return h.hexdigest()[:12]\n",
    "\n",
    "def get_sparql(query, max_retries=3):\n",
    "    \"\"\"Execute SPARQL query with caching and retry logic.\"\"\"\n",
    "    qhash = query_hash(query)\n",
    "    cache_file = os.path.join(CACHE_DIR, f\"{qhash}.json\")\n",
    "    \n",
    "    if os.path.exists(cache_file):\n",
    "        with open(cache_file, \"r\") as f:\n",
    "            print(f\"[cache] {qhash}\")\n",
    "            return json.load(f)\n",
    "    \n",
    "    sparql = SPARQLWrapper(ENDPOINT_URL, agent=USER_AGENT)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"[query] {qhash}...\")\n",
    "            result = sparql.query().convert()\n",
    "            \n",
    "            with open(cache_file, \"w\") as f:\n",
    "                json.dump(result, f)\n",
    "            \n",
    "            print(f\"[saved] {qhash}\")\n",
    "            time.sleep(2)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                wait = (attempt + 1) * 5\n",
    "                print(f\"[retry] Attempt {attempt + 1} failed: {e}\")\n",
    "                time.sleep(wait)\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "def get_count(query):\n",
    "    result = get_sparql(query)\n",
    "    return int(result[\"results\"][\"bindings\"][0][\"count\"][\"value\"])\n",
    "\n",
    "def get_bindings(query):\n",
    "    result = get_sparql(query)\n",
    "    return result[\"results\"][\"bindings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ENTITY FETCHING WITH PARALLEL SUPPORT\n",
    "# =============================================================================\n",
    "\n",
    "# In-memory entity cache for fast repeated access\n",
    "ENTITY_CACHE = {}\n",
    "\n",
    "def get_entity_from_disk(qid):\n",
    "    \"\"\"Load entity from disk cache only.\"\"\"\n",
    "    cache_file = os.path.join(CACHE_DIR, f\"{qid}.json\")\n",
    "    if os.path.exists(cache_file):\n",
    "        with open(cache_file, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    return None\n",
    "\n",
    "def fetch_entity_http(qid):\n",
    "    \"\"\"Fetch a single entity from HTTP (for parallel fetching).\"\"\"\n",
    "    global CURRENT_DELAY\n",
    "    \n",
    "    cache_file = os.path.join(CACHE_DIR, f\"{qid}.json\")\n",
    "    url = ENTITY_URL_TEMPLATE.format(qid)\n",
    "    \n",
    "    max_retries = 5\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            req = urllib.request.Request(url, headers={\"User-Agent\": USER_AGENT})\n",
    "            with urllib.request.urlopen(req, timeout=30) as response:\n",
    "                data = json.loads(response.read().decode(\"utf-8\"))\n",
    "                \n",
    "                if \"entities\" not in data or qid not in data[\"entities\"]:\n",
    "                    with open(cache_file, \"w\") as f:\n",
    "                        json.dump(None, f)\n",
    "                    return qid, None\n",
    "                \n",
    "                entity = data[\"entities\"][qid]\n",
    "                \n",
    "                if \"missing\" in entity:\n",
    "                    with open(cache_file, \"w\") as f:\n",
    "                        json.dump(None, f)\n",
    "                    return qid, None\n",
    "                \n",
    "                with open(cache_file, \"w\") as f:\n",
    "                    json.dump(entity, f)\n",
    "                \n",
    "                return qid, entity\n",
    "                \n",
    "        except urllib.error.HTTPError as e:\n",
    "            if e.code == 429:\n",
    "                wait = min(MAX_DELAY, CURRENT_DELAY * (2 ** attempt))\n",
    "                time.sleep(wait)\n",
    "                continue\n",
    "            elif e.code == 404:\n",
    "                with open(cache_file, \"w\") as f:\n",
    "                    json.dump(None, f)\n",
    "                return qid, None\n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "            return qid, None\n",
    "    \n",
    "    return qid, None\n",
    "\n",
    "def get_entity(qid):\n",
    "    \"\"\"Get entity from memory cache, disk cache, or fetch.\"\"\"\n",
    "    # Check memory cache first\n",
    "    if qid in ENTITY_CACHE:\n",
    "        return ENTITY_CACHE[qid]\n",
    "    \n",
    "    # Check disk cache\n",
    "    entity = get_entity_from_disk(qid)\n",
    "    if entity is not None or os.path.exists(os.path.join(CACHE_DIR, f\"{qid}.json\")):\n",
    "        ENTITY_CACHE[qid] = entity\n",
    "        return entity\n",
    "    \n",
    "    # Fetch from HTTP\n",
    "    _, entity = fetch_entity_http(qid)\n",
    "    ENTITY_CACHE[qid] = entity\n",
    "    return entity\n",
    "\n",
    "def batch_fetch_entities(qids, desc=\"entities\", max_workers=MAX_WORKERS):\n",
    "    \"\"\"\n",
    "    Fetch multiple entities in parallel.\n",
    "    Returns dict of qid -> entity.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    to_fetch = []\n",
    "    \n",
    "    # Check what we already have\n",
    "    for qid in qids:\n",
    "        if qid in ENTITY_CACHE:\n",
    "            results[qid] = ENTITY_CACHE[qid]\n",
    "        else:\n",
    "            entity = get_entity_from_disk(qid)\n",
    "            if entity is not None or os.path.exists(os.path.join(CACHE_DIR, f\"{qid}.json\")):\n",
    "                ENTITY_CACHE[qid] = entity\n",
    "                results[qid] = entity\n",
    "            else:\n",
    "                to_fetch.append(qid)\n",
    "    \n",
    "    if not to_fetch:\n",
    "        print(f\"[{timestamp()}] All {len(qids):,} {desc} already cached\")\n",
    "        return results\n",
    "    \n",
    "    print(f\"[{timestamp()}] Fetching {len(to_fetch):,} {desc} ({len(results):,} cached)...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    fetched = 0\n",
    "    errors = 0\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(fetch_entity_http, qid): qid for qid in to_fetch}\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            qid, entity = future.result()\n",
    "            ENTITY_CACHE[qid] = entity\n",
    "            results[qid] = entity\n",
    "            \n",
    "            if entity is None:\n",
    "                errors += 1\n",
    "            \n",
    "            fetched += 1\n",
    "            if fetched % 100 == 0 or fetched == len(to_fetch):\n",
    "                elapsed = time.time() - start_time\n",
    "                rate = fetched / elapsed if elapsed > 0 else 0\n",
    "                remaining = (len(to_fetch) - fetched) / rate if rate > 0 else 0\n",
    "                print(f\"[{timestamp()}] [fetch] {fetched:,}/{len(to_fetch):,} @ {rate:.1f}/s | ~{format_time_remaining(remaining)} remaining\")\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"[{timestamp()}] [done] Fetched {len(to_fetch):,} {desc} in {elapsed/60:.1f} minutes ({errors:,} errors)\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ENTITY DATA EXTRACTION UTILITIES\n",
    "# =============================================================================\n",
    "\n",
    "def get_label(qid, lang=\"en\"):\n",
    "    \"\"\"Get label for a Q-ID.\"\"\"\n",
    "    entity = get_entity(qid)\n",
    "    if entity is None:\n",
    "        return qid\n",
    "    \n",
    "    labels = entity.get(\"labels\", {})\n",
    "    if lang in labels:\n",
    "        return labels[lang][\"value\"]\n",
    "    elif \"en\" in labels:\n",
    "        return labels[\"en\"][\"value\"]\n",
    "    elif labels:\n",
    "        return list(labels.values())[0][\"value\"]\n",
    "    return qid\n",
    "\n",
    "def get_claim_values(entity, property_id):\n",
    "    \"\"\"Extract Q-IDs from a property's claims.\"\"\"\n",
    "    if entity is None:\n",
    "        return []\n",
    "    \n",
    "    claims = entity.get(\"claims\", {}).get(property_id, [])\n",
    "    values = []\n",
    "    for claim in claims:\n",
    "        mainsnak = claim.get(\"mainsnak\", {})\n",
    "        datavalue = mainsnak.get(\"datavalue\", {})\n",
    "        if datavalue.get(\"type\") == \"wikibase-entityid\":\n",
    "            values.append(datavalue[\"value\"][\"id\"])\n",
    "    return values\n",
    "\n",
    "def get_claim_time_values(entity, property_id):\n",
    "    \"\"\"Extract time values from a property's claims.\"\"\"\n",
    "    if entity is None:\n",
    "        return []\n",
    "    claims = entity.get(\"claims\", {}).get(property_id, [])\n",
    "    values = []\n",
    "    for claim in claims:\n",
    "        mainsnak = claim.get(\"mainsnak\", {})\n",
    "        datavalue = mainsnak.get(\"datavalue\", {})\n",
    "        if datavalue.get(\"type\") == \"time\":\n",
    "            values.append(datavalue[\"value\"][\"time\"])\n",
    "    return values\n",
    "\n",
    "def get_creation_year(entity):\n",
    "    \"\"\"Extract creation year from P571 (inception) or P577 (publication date).\"\"\"\n",
    "    for prop in [\"P571\", \"P577\"]:\n",
    "        claims = entity.get(\"claims\", {}).get(prop, [])\n",
    "        for claim in claims:\n",
    "            try:\n",
    "                time_value = claim.get(\"mainsnak\", {}).get(\"datavalue\", {}).get(\"value\", {}).get(\"time\", \"\")\n",
    "                if time_value:\n",
    "                    year_str = time_value[1:5]\n",
    "                    return int(year_str)\n",
    "            except (KeyError, ValueError, TypeError):\n",
    "                continue\n",
    "    return None\n",
    "\n",
    "def parse_date(time_str):\n",
    "    \"\"\"Parse Wikidata time format to (year, month, day) tuple.\"\"\"\n",
    "    try:\n",
    "        # Format: +1503-00-00T00:00:00Z or +1503-01-01T00:00:00Z\n",
    "        sign = 1 if time_str[0] == '+' else -1\n",
    "        year = int(time_str[1:5]) * sign\n",
    "        month = int(time_str[6:8]) or 1\n",
    "        day = int(time_str[9:11]) or 1\n",
    "        return (year, month, day)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 1: GET PAINTING QIDs FROM SPARQL\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"[{timestamp()}] Fetching painting Q-IDs from SPARQL...\")\n",
    "\n",
    "# Total paintings count\n",
    "query_total = \"\"\"\n",
    "SELECT (COUNT(?painting) AS ?count)\n",
    "WHERE {\n",
    "  ?painting wdt:P31/wdt:P279* wd:Q3305213.\n",
    "}\n",
    "\"\"\"\n",
    "total_paintings = get_count(query_total)\n",
    "print(f\"[{timestamp()}] Total paintings: {total_paintings:,}\")\n",
    "\n",
    "# Get all painting QIDs\n",
    "query_all_paintings = \"\"\"\n",
    "SELECT ?painting WHERE {\n",
    "  ?painting wdt:P31/wdt:P279* wd:Q3305213.\n",
    "}\n",
    "\"\"\"\n",
    "bindings = get_bindings(query_all_paintings)\n",
    "painting_qids = [b[\"painting\"][\"value\"].split(\"/\")[-1] for b in bindings]\n",
    "print(f\"[{timestamp()}] Loaded {len(painting_qids):,} painting QIDs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 2: BATCH FETCH ALL PAINTING ENTITIES\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n[{timestamp()}] {'='*60}\")\n",
    "print(f\"[{timestamp()}] BATCH LOADING PAINTING ENTITIES\")\n",
    "print(f\"[{timestamp()}] {'='*60}\")\n",
    "\n",
    "painting_entities = batch_fetch_entities(painting_qids, desc=\"paintings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 3: SINGLE-PASS PAINTING SCAN\n",
    "# Extract ALL painting properties in ONE loop!\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n[{timestamp()}] {'='*60}\")\n",
    "print(f\"[{timestamp()}] SINGLE-PASS PAINTING SCAN\")\n",
    "print(f\"[{timestamp()}] {'='*60}\")\n",
    "\n",
    "# Initialize counters and collections\n",
    "movement_counts = Counter()        # P135: movement\n",
    "material_counts = Counter()        # P186: material used\n",
    "genre_counts = Counter()           # P136: genre\n",
    "collection_counts = Counter()      # P195: collection\n",
    "\n",
    "paintings_with_creator = set()\n",
    "paintings_with_movement = set()\n",
    "paintings_with_material = set()\n",
    "paintings_with_genre = set()\n",
    "paintings_with_collection = set()\n",
    "paintings_with_year = set()\n",
    "\n",
    "all_creator_qids = set()           # Collect all unique creators\n",
    "creator_painting_count = Counter() # How many paintings per creator\n",
    "\n",
    "# For timeline: painting year + movement pairs\n",
    "painting_year_movement = []        # List of (year, movement_qid) tuples\n",
    "painting_years = []                # All painting years for histogram\n",
    "decade_counts = Counter()          # For inception chart\n",
    "\n",
    "# For genre timelines\n",
    "TIMELINE_GENRES = {\n",
    "    \"Q134307\": \"portrait\",      # portrait\n",
    "    \"Q2864737\": \"religious\",    # religious art\n",
    "    \"Q191163\": \"landscape\",     # landscape painting\n",
    "}\n",
    "genre_decade_counts = {genre: Counter() for genre in TIMELINE_GENRES.values()}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i, qid in enumerate(painting_qids):\n",
    "    if (i + 1) % 100000 == 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        rate = (i + 1) / elapsed\n",
    "        remaining = (len(painting_qids) - i - 1) / rate\n",
    "        print(f\"[{timestamp()}] [scan] {i + 1:,}/{len(painting_qids):,} @ {rate:.0f}/s | ~{format_time_remaining(remaining)}\")\n",
    "    \n",
    "    entity = painting_entities.get(qid)\n",
    "    if entity is None:\n",
    "        continue\n",
    "    \n",
    "    # --- MOVEMENTS (P135) ---\n",
    "    movements = get_claim_values(entity, \"P135\")\n",
    "    if movements:\n",
    "        paintings_with_movement.add(qid)\n",
    "        for m in movements:\n",
    "            movement_counts[m] += 1\n",
    "    \n",
    "    # --- MATERIALS (P186) ---\n",
    "    materials = get_claim_values(entity, \"P186\")\n",
    "    if materials:\n",
    "        paintings_with_material.add(qid)\n",
    "        for m in materials:\n",
    "            material_counts[m] += 1\n",
    "    \n",
    "    # --- GENRES (P136) ---\n",
    "    genres = get_claim_values(entity, \"P136\")\n",
    "    if genres:\n",
    "        paintings_with_genre.add(qid)\n",
    "        for g in genres:\n",
    "            genre_counts[g] += 1\n",
    "    \n",
    "    # --- COLLECTIONS (P195) ---\n",
    "    collections = get_claim_values(entity, \"P195\")\n",
    "    if collections:\n",
    "        paintings_with_collection.add(qid)\n",
    "        for c in collections:\n",
    "            collection_counts[c] += 1\n",
    "    \n",
    "    # --- CREATORS (P170) ---\n",
    "    creators = get_claim_values(entity, \"P170\")\n",
    "    for c in creators:\n",
    "        all_creator_qids.add(c)\n",
    "        creator_painting_count[c] += 1\n",
    "    if creators:\n",
    "        paintings_with_creator.add(qid)\n",
    "\n",
    "    # --- CREATION YEAR (P571/P577) ---\n",
    "    year = get_creation_year(entity)\n",
    "    if year is not None and 1000 <= year <= 2030:\n",
    "        paintings_with_year.add(qid)\n",
    "        painting_years.append(year)\n",
    "        \n",
    "        # Decade for inception chart\n",
    "        decade = (year // 10) * 10\n",
    "        decade_counts[decade] += 1\n",
    "        \n",
    "        # Store year + movements for timeline\n",
    "        for m in movements:\n",
    "            painting_year_movement.append((year, m))\n",
    "        \n",
    "        # Store year + genres for genre timeline\n",
    "        for genre_qid, genre_name in TIMELINE_GENRES.items():\n",
    "            if genre_qid in genres:\n",
    "                genre_decade_counts[genre_name][decade] += 1\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n[{timestamp()}] PAINTING SCAN COMPLETE in {elapsed/60:.1f} minutes\")\n",
    "print(f\"[{timestamp()}] Unique creators found: {len(all_creator_qids):,}\")\n",
    "print(f\"[{timestamp()}] Paintings with movement: {len(paintings_with_movement):,}\")\n",
    "print(f\"[{timestamp()}] Paintings with material: {len(paintings_with_material):,}\")\n",
    "print(f\"[{timestamp()}] Paintings with genre: {len(paintings_with_genre):,}\")\n",
    "print(f\"[{timestamp()}] Paintings with collection: {len(paintings_with_collection):,}\")\n",
    "print(f\"[{timestamp()}] Paintings with year: {len(paintings_with_year):,}\")\n",
    "print(f\"[{timestamp()}] Paintings with creator: {len(paintings_with_creator):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[{timestamp()}] Paintings with creator: {len(paintings_with_creator):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 4: BATCH FETCH ALL CREATOR ENTITIES\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n[{timestamp()}] {'='*60}\")\n",
    "print(f\"[{timestamp()}] BATCH LOADING CREATOR ENTITIES\")\n",
    "print(f\"[{timestamp()}] {'='*60}\")\n",
    "\n",
    "all_creator_qids = list(all_creator_qids)  # Convert to list for indexing\n",
    "creator_entities = batch_fetch_entities(all_creator_qids, desc=\"creators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 5: SINGLE-PASS CREATOR SCAN\n",
    "# Extract ALL creator properties in ONE loop!\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n[{timestamp()}] {'='*60}\")\n",
    "print(f\"[{timestamp()}] SINGLE-PASS CREATOR SCAN\")\n",
    "print(f\"[{timestamp()}] {'='*60}\")\n",
    "\n",
    "# Initialize counters\n",
    "gender_counts = Counter()          # P21: sex or gender\n",
    "birthplace_counts = Counter()      # P19: place of birth\n",
    "nationality_counts = Counter()     # P27: country of citizenship\n",
    "\n",
    "creators_with_gender = 0\n",
    "creators_with_birthplace = 0\n",
    "creators_with_nationality = 0\n",
    "\n",
    "# For movement inheritance\n",
    "creator_movements = {}             # creator_qid -> list of movement qids\n",
    "\n",
    "# For country/continent analysis\n",
    "creator_birthplaces = {}           # creator_qid -> birthplace_qid\n",
    "birthplace_qids = set()            # All unique birthplaces\n",
    "\n",
    "# For lifespan analysis\n",
    "artist_data = []                   # List of dicts with birth/death/lifespan info\n",
    "missing_birth = 0\n",
    "missing_death = 0\n",
    "\n",
    "def calculate_lifespan(birth_date, death_date):\n",
    "    if birth_date is None or death_date is None:\n",
    "        return None\n",
    "    b_year, b_month, b_day = birth_date\n",
    "    d_year, d_month, d_day = death_date\n",
    "    birth_days = b_year * 365.25 + (b_month - 1) * 30.44 + b_day\n",
    "    death_days = d_year * 365.25 + (d_month - 1) * 30.44 + d_day\n",
    "    lifespan = (death_days - birth_days) / 365.25\n",
    "    return round(lifespan, 2)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i, creator_qid in enumerate(all_creator_qids):\n",
    "    if (i + 1) % 10000 == 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        rate = (i + 1) / elapsed\n",
    "        remaining = (len(all_creator_qids) - i - 1) / rate\n",
    "        print(f\"[{timestamp()}] [scan] {i + 1:,}/{len(all_creator_qids):,} @ {rate:.0f}/s | ~{format_time_remaining(remaining)}\")\n",
    "    \n",
    "    entity = creator_entities.get(creator_qid)\n",
    "    if entity is None:\n",
    "        continue\n",
    "    \n",
    "    # --- GENDER (P21) ---\n",
    "    genders = get_claim_values(entity, \"P21\")\n",
    "    if genders:\n",
    "        creators_with_gender += 1\n",
    "        for g in genders:\n",
    "            gender_counts[g] += 1\n",
    "    \n",
    "    # --- BIRTHPLACE (P19) ---\n",
    "    birthplaces = get_claim_values(entity, \"P19\")\n",
    "    if birthplaces:\n",
    "        creators_with_birthplace += 1\n",
    "        creator_birthplaces[creator_qid] = birthplaces[0]\n",
    "        birthplace_qids.add(birthplaces[0])\n",
    "        for b in birthplaces:\n",
    "            birthplace_counts[b] += 1\n",
    "    \n",
    "    # --- NATIONALITY (P27) ---\n",
    "    nationalities = get_claim_values(entity, \"P27\")\n",
    "    if nationalities:\n",
    "        creators_with_nationality += 1\n",
    "        for n in nationalities:\n",
    "            nationality_counts[n] += 1\n",
    "    \n",
    "    # --- MOVEMENTS (P135) for inheritance ---\n",
    "    movements = get_claim_values(entity, \"P135\")\n",
    "    if movements:\n",
    "        creator_movements[creator_qid] = movements\n",
    "    \n",
    "    # --- BIRTH/DEATH DATES for lifespan ---\n",
    "    birth_dates = get_claim_time_values(entity, \"P569\")\n",
    "    death_dates = get_claim_time_values(entity, \"P570\")\n",
    "    \n",
    "    birth_date = parse_date(birth_dates[0]) if birth_dates else None\n",
    "    death_date = parse_date(death_dates[0]) if death_dates else None\n",
    "    \n",
    "    if birth_date is None:\n",
    "        missing_birth += 1\n",
    "    if death_date is None:\n",
    "        missing_death += 1\n",
    "    \n",
    "    lifespan = calculate_lifespan(birth_date, death_date)\n",
    "    \n",
    "    if lifespan is not None and 10 <= lifespan <= 120:\n",
    "        notable_works = get_claim_values(entity, \"P800\")\n",
    "        works_in_dataset = creator_painting_count.get(creator_qid, 0)\n",
    "        \n",
    "        artist_data.append({\n",
    "            \"qid\": creator_qid,\n",
    "            \"birth_year\": birth_date[0],\n",
    "            \"death_year\": death_date[0],\n",
    "            \"lifespan\": lifespan,\n",
    "            \"notable_works\": len(notable_works) if notable_works else 0,\n",
    "            \"works_in_dataset\": works_in_dataset\n",
    "        })\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n[{timestamp()}] CREATOR SCAN COMPLETE in {elapsed/60:.1f} minutes\")\n",
    "print(f\"[{timestamp()}] Creators with gender: {creators_with_gender:,}\")\n",
    "print(f\"[{timestamp()}] Creators with birthplace: {creators_with_birthplace:,}\")\n",
    "print(f\"[{timestamp()}] Creators with nationality: {creators_with_nationality:,}\")\n",
    "print(f\"[{timestamp()}] Creators with movements: {len(creator_movements):,}\")\n",
    "print(f\"[{timestamp()}] Artists with lifespan data: {len(artist_data):,}\")\n",
    "print(f\"[{timestamp()}] Unique birthplaces: {len(birthplace_qids):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 6: RESOLVE BIRTHPLACES TO COUNTRIES AND CONTINENTS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n[{timestamp()}] {'='*60}\")\n",
    "print(f\"[{timestamp()}] RESOLVING BIRTHPLACES TO COUNTRIES\")\n",
    "print(f\"[{timestamp()}] {'='*60}\")\n",
    "\n",
    "# Fetch birthplace entities\n",
    "birthplace_entities = batch_fetch_entities(list(birthplace_qids), desc=\"birthplaces\")\n",
    "\n",
    "# Resolve birthplace -> country\n",
    "birthplace_to_country = {}\n",
    "country_qids = set()\n",
    "\n",
    "for bp_qid in birthplace_qids:\n",
    "    bp_entity = birthplace_entities.get(bp_qid)\n",
    "    if bp_entity:\n",
    "        countries = get_claim_values(bp_entity, \"P17\")  # P17 = country\n",
    "        if countries:\n",
    "            country_qid = countries[0]\n",
    "            birthplace_to_country[bp_qid] = country_qid\n",
    "            country_qids.add(country_qid)\n",
    "\n",
    "print(f\"[{timestamp()}] Birthplaces with country: {len(birthplace_to_country):,}\")\n",
    "print(f\"[{timestamp()}] Unique countries: {len(country_qids):,}\")\n",
    "\n",
    "# Fetch country entities to get continents\n",
    "country_entities = batch_fetch_entities(list(country_qids), desc=\"countries\")\n",
    "\n",
    "# Resolve country -> continent\n",
    "country_to_continent = {}\n",
    "for country_qid in country_qids:\n",
    "    country_entity = country_entities.get(country_qid)\n",
    "    if country_entity:\n",
    "        continents = get_claim_values(country_entity, \"P30\")  # P30 = continent\n",
    "        if continents:\n",
    "            country_to_continent[country_qid] = continents[0]\n",
    "\n",
    "print(f\"[{timestamp()}] Countries with continent: {len(country_to_continent):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 7: COUNT CREATORS BY COUNTRY AND CONTINENT\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n[{timestamp()}] Counting creators per country and continent...\")\n",
    "\n",
    "country_counts = Counter()\n",
    "continent_counts = Counter()\n",
    "creators_with_country = 0\n",
    "no_country_count = 0\n",
    "\n",
    "for creator_qid, birthplace_qid in creator_birthplaces.items():\n",
    "    country_qid = birthplace_to_country.get(birthplace_qid)\n",
    "    if country_qid:\n",
    "        country_counts[country_qid] += 1\n",
    "        creators_with_country += 1\n",
    "        \n",
    "        # Also count by continent\n",
    "        continent_qid = country_to_continent.get(country_qid)\n",
    "        if continent_qid:\n",
    "            continent_counts[continent_qid] += 1\n",
    "    else:\n",
    "        no_country_count += 1\n",
    "\n",
    "# Add creators without any birthplace\n",
    "no_country_count += len(all_creator_qids) - len(creator_birthplaces)\n",
    "\n",
    "print(f\"[{timestamp()}] Creators with country: {creators_with_country:,}\")\n",
    "print(f\"[{timestamp()}] Creators without country: {no_country_count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 8: SECOND PAINTING PASS - Add inherited movements\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n[{timestamp()}] {'='*60}\")\n",
    "print(f\"[{timestamp()}] ADDING INHERITED MOVEMENTS\")\n",
    "print(f\"[{timestamp()}] {'='*60}\")\n",
    "\n",
    "# Rebuild movement counts including creator movements\n",
    "movement_counts_with_inheritance = Counter()\n",
    "paintings_with_movement_inherited = set()\n",
    "painting_year_movement_inherited = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i, qid in enumerate(painting_qids):\n",
    "    if (i + 1) % 100000 == 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        rate = (i + 1) / elapsed\n",
    "        print(f\"[{timestamp()}] [inherit] {i + 1:,}/{len(painting_qids):,} @ {rate:.0f}/s\")\n",
    "    \n",
    "    entity = painting_entities.get(qid)\n",
    "    if entity is None:\n",
    "        continue\n",
    "    \n",
    "    # Direct movements\n",
    "    all_movements = set(get_claim_values(entity, \"P135\"))\n",
    "    \n",
    "    # Add creator movements\n",
    "    for creator_qid in get_claim_values(entity, \"P170\"):\n",
    "        if creator_qid in creator_movements:\n",
    "            all_movements.update(creator_movements[creator_qid])\n",
    "    \n",
    "    if all_movements:\n",
    "        paintings_with_movement_inherited.add(qid)\n",
    "        for m in all_movements:\n",
    "            movement_counts_with_inheritance[m] += 1\n",
    "        \n",
    "        # For timeline\n",
    "        year = get_creation_year(entity)\n",
    "        if year is not None and 1000 <= year <= 2030:\n",
    "            for m in all_movements:\n",
    "                painting_year_movement_inherited.append((year, m))\n",
    "\n",
    "print(f\"[{timestamp()}] Paintings with movement (with inheritance): {len(paintings_with_movement_inherited):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZATION GENERATION UTILITIES\n",
    "# =============================================================================\n",
    "\n",
    "def clean_movement_label(label):\n",
    "    \"\"\"Clean up movement labels.\"\"\"\n",
    "    if label.lower().endswith(\" painting\"):\n",
    "        label = label[:-9]\n",
    "    return label.title()\n",
    "\n",
    "def create_bar_chart(data, field_name, output_name, title=\"\"):\n",
    "    \"\"\"Create a Vega-Lite bar chart specification.\"\"\"\n",
    "    sort_order = [d[field_name] for d in data]\n",
    "    \n",
    "    spec = {\n",
    "        \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n",
    "        \"data\": {\"values\": data},\n",
    "        \"mark\": {\"type\": \"bar\", \"color\": \"#999999\"},\n",
    "        \"encoding\": {\n",
    "            \"y\": {\n",
    "                \"field\": field_name,\n",
    "                \"type\": \"nominal\",\n",
    "                \"sort\": sort_order,\n",
    "                \"title\": \"\"\n",
    "            },\n",
    "            \"x\": {\n",
    "                \"field\": \"count\",\n",
    "                \"type\": \"quantitative\",\n",
    "                \"title\": \"\"\n",
    "            }\n",
    "        },\n",
    "        \"width\": 300,\n",
    "        \"height\": 400\n",
    "    }\n",
    "    \n",
    "    output_path = os.path.join(VIS_DIR, f\"{output_name}.json\")\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(spec, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"[{timestamp()}] Output: {output_path}\")\n",
    "    return spec\n",
    "\n",
    "def create_chart_from_counts(counts, field_name, output_name, top_n=20, label_transform=None):\n",
    "    \"\"\"Create a bar chart from a Counter, fetching labels.\"\"\"\n",
    "    print(f\"\\n[{timestamp()}] Creating {output_name} chart...\")\n",
    "    \n",
    "    top_items = counts.most_common(top_n + 10)  # Fetch extra for merging\n",
    "    \n",
    "    # Build data with labels\n",
    "    data = []\n",
    "    for qid, count in top_items:\n",
    "        label = get_label(qid)\n",
    "        if label_transform:\n",
    "            label = label_transform(label)\n",
    "        data.append({field_name: label, \"count\": count, \"qid\": qid})\n",
    "        print(f\"[{timestamp()}]   {qid} -> {label}: {count:,}\")\n",
    "    \n",
    "    # Collapse duplicates by lowercase\n",
    "    collapsed = {}\n",
    "    for item in data:\n",
    "        label_lower = item[field_name].lower()\n",
    "        if label_lower in collapsed:\n",
    "            collapsed[label_lower][\"count\"] += item[\"count\"]\n",
    "        else:\n",
    "            collapsed[label_lower] = {field_name: item[field_name], \"count\": item[\"count\"]}\n",
    "    \n",
    "    final_data = sorted(collapsed.values(), key=lambda x: x[\"count\"], reverse=True)[:top_n]\n",
    "    \n",
    "    # Calculate \"Other\"\n",
    "    top_counts = sum(d[\"count\"] for d in final_data)\n",
    "    other_count = sum(counts.values()) - top_counts\n",
    "    if other_count > 0:\n",
    "        final_data.append({field_name: \"Other\", \"count\": other_count})\n",
    "    \n",
    "    return create_bar_chart(final_data, field_name, output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GENERATE BASIC BAR CHARTS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n[{timestamp()}] {'='*60}\")\n",
    "print(f\"[{timestamp()}] GENERATING VISUALIZATIONS\")\n",
    "print(f\"[{timestamp()}] {'='*60}\")\n",
    "\n",
    "# --- MOVEMENTS ---\n",
    "create_chart_from_counts(\n",
    "    movement_counts_with_inheritance, \n",
    "    \"movement\", \n",
    "    \"movements\",\n",
    "    label_transform=clean_movement_label\n",
    ")\n",
    "\n",
    "# --- MATERIALS ---\n",
    "create_chart_from_counts(\n",
    "    material_counts, \n",
    "    \"material\", \n",
    "    \"materials\",\n",
    "    label_transform=lambda x: x.title()\n",
    ")\n",
    "\n",
    "# --- GENRES ---\n",
    "create_chart_from_counts(\n",
    "    genre_counts, \n",
    "    \"genre\", \n",
    "    \"genre\",\n",
    "    label_transform=lambda x: x.title()\n",
    ")\n",
    "\n",
    "# --- COLLECTIONS ---\n",
    "create_chart_from_counts(\n",
    "    collection_counts, \n",
    "    \"collection\", \n",
    "    \"collection\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COUNTRY BAR CHART\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n[{timestamp()}] Creating country chart...\")\n",
    "\n",
    "TOP_N = 20\n",
    "top_countries = country_counts.most_common(TOP_N)\n",
    "\n",
    "country_data = []\n",
    "for qid, count in top_countries:\n",
    "    label = get_label(qid)\n",
    "    country_data.append({\"country\": label, \"count\": count})\n",
    "    print(f\"[{timestamp()}]   {qid} -> {label}: {count:,}\")\n",
    "\n",
    "country_spec = {\n",
    "    \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n",
    "    \"data\": {\"values\": country_data},\n",
    "    \"mark\": {\"type\": \"bar\", \"color\": \"#999999\"},\n",
    "    \"encoding\": {\n",
    "        \"y\": {\n",
    "            \"field\": \"country\",\n",
    "            \"type\": \"nominal\",\n",
    "            \"sort\": \"-x\",\n",
    "            \"title\": \"\"\n",
    "        },\n",
    "        \"x\": {\n",
    "            \"field\": \"count\",\n",
    "            \"type\": \"quantitative\",\n",
    "            \"title\": \"\"\n",
    "        }\n",
    "    },\n",
    "    \"width\": 300,\n",
    "    \"height\": 300\n",
    "}\n",
    "\n",
    "output_path = os.path.join(VIS_DIR, \"country.json\")\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(country_spec, f, ensure_ascii=False, indent=2)\n",
    "print(f\"[{timestamp()}] Output: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONTINENT BAR CHART\n",
    "# =============================================================================\n",
    "print(f\"\\n[{timestamp()}] Creating continent chart...\")\n",
    "\n",
    "# Exclude non-standard continent entries\n",
    "EXCLUDE_CONTINENT_QIDS = {\n",
    "    \"Q5401\",    # Eurasia\n",
    "    \"Q27611\",   # Central America\n",
    "    \"Q828\",     # Americas\n",
    "}\n",
    "\n",
    "# Western continents (not highlighted)\n",
    "WESTERN_CONTINENT_QIDS = {\n",
    "    \"Q46\",      # Europe\n",
    "    \"Q49\",      # North America\n",
    "}\n",
    "\n",
    "top_continents = continent_counts.most_common(10)\n",
    "continent_data = []\n",
    "for qid, count in top_continents:\n",
    "    if qid in EXCLUDE_CONTINENT_QIDS:\n",
    "        print(f\"[{timestamp()}]   {qid} -> (excluded): {count:,}\")\n",
    "        continue\n",
    "    \n",
    "    label = get_label(qid)\n",
    "    # Handle Oceania special case (Q55643 sometimes shows as \"Australia\")\n",
    "    if qid == \"Q538\":\n",
    "        label = \"Oceania\"\n",
    "    \n",
    "    # Highlight non-Western continents\n",
    "    is_global_south = qid not in WESTERN_CONTINENT_QIDS\n",
    "    \n",
    "    continent_data.append({\n",
    "        \"continent\": label,\n",
    "        \"count\": count,\n",
    "        \"global_south\": is_global_south\n",
    "    })\n",
    "    print(f\"[{timestamp()}]   {qid} -> {label}: {count:,} {'(highlighted)' if is_global_south else ''}\")\n",
    "\n",
    "continent_spec = {\n",
    "    \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n",
    "    \"data\": {\"values\": continent_data},\n",
    "    \"mark\": {\"type\": \"bar\"},\n",
    "    \"encoding\": {\n",
    "        \"y\": {\n",
    "            \"field\": \"continent\",\n",
    "            \"type\": \"nominal\",\n",
    "            \"sort\": \"-x\",\n",
    "            \"title\": \"\"\n",
    "        },\n",
    "        \"x\": {\n",
    "            \"field\": \"count\",\n",
    "            \"type\": \"quantitative\",\n",
    "            \"title\": \"\"\n",
    "        },\n",
    "        \"color\": {\n",
    "            \"field\": \"global_south\",\n",
    "            \"type\": \"nominal\",\n",
    "            \"scale\": {\n",
    "                \"domain\": [True, False],\n",
    "                \"range\": [\"#FF00D3\", \"#999999\"]\n",
    "            },\n",
    "            \"legend\": None\n",
    "        }\n",
    "    },\n",
    "    \"width\": 300,\n",
    "    \"height\": 200\n",
    "}\n",
    "\n",
    "output_path = os.path.join(VIS_DIR, \"continent.json\")\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(continent_spec, f, ensure_ascii=False, indent=2)\n",
    "print(f\"[{timestamp()}] Output: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GLOBAL SOUTH PAINTER RATIO BY BIRTH DECADE\n",
    "# =============================================================================\n",
    "print(f\"\\n[{timestamp()}] Calculating Global South painter ratio by birth decade...\")\n",
    "\n",
    "# Define Europe and North America continent QIDs to exclude\n",
    "EUROPE_QID = \"Q46\"\n",
    "NORTH_AMERICA_QID = \"Q49\"\n",
    "WESTERN_CONTINENTS = {EUROPE_QID, NORTH_AMERICA_QID}\n",
    "\n",
    "# Count total and Global South artists per birth decade\n",
    "birth_decade_total_geo = Counter()\n",
    "birth_decade_global_south = Counter()\n",
    "\n",
    "for creator_qid in all_creator_qids:\n",
    "    entity = creator_entities.get(creator_qid)\n",
    "    if entity is None:\n",
    "        continue\n",
    "    \n",
    "    # Get birth date\n",
    "    birth_dates = get_claim_time_values(entity, \"P569\")\n",
    "    if not birth_dates:\n",
    "        continue\n",
    "    \n",
    "    birth_date = parse_date(birth_dates[0])\n",
    "    if birth_date is None:\n",
    "        continue\n",
    "    \n",
    "    birth_year = birth_date[0]\n",
    "    if birth_year < 1500 or birth_year > 1980:\n",
    "        continue\n",
    "    \n",
    "    # Get birthplace -> country -> continent\n",
    "    birthplace_qid = creator_birthplaces.get(creator_qid)\n",
    "    if not birthplace_qid:\n",
    "        continue\n",
    "    \n",
    "    country_qid = birthplace_to_country.get(birthplace_qid)\n",
    "    if not country_qid:\n",
    "        continue\n",
    "    \n",
    "    continent_qid = country_to_continent.get(country_qid)\n",
    "    if not continent_qid:\n",
    "        continue\n",
    "    \n",
    "    decade = (birth_year // 10) * 10\n",
    "    birth_decade_total_geo[decade] += 1\n",
    "    \n",
    "    # Check if NOT Europe or North America\n",
    "    if continent_qid not in WESTERN_CONTINENTS:\n",
    "        birth_decade_global_south[decade] += 1\n",
    "\n",
    "# Build timeline data\n",
    "geo_timeline_data = []\n",
    "for decade in sorted(birth_decade_total_geo.keys()):\n",
    "    total = birth_decade_total_geo[decade]\n",
    "    global_south = birth_decade_global_south.get(decade, 0)\n",
    "    \n",
    "    if total >= 10:  # Only include decades with enough data\n",
    "        pct = (global_south / total) * 100\n",
    "        geo_timeline_data.append({\n",
    "            \"decade\": decade,\n",
    "            \"percentage\": round(pct, 2),\n",
    "            \"global_south\": global_south,\n",
    "            \"total\": total\n",
    "        })\n",
    "\n",
    "print(f\"[{timestamp()}] Decades with data: {len(geo_timeline_data)}\")\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\n[{timestamp()}] Global South painter percentage by century:\")\n",
    "for century_start in range(1500, 2000, 100):\n",
    "    century_data = [d for d in geo_timeline_data if century_start <= d[\"decade\"] < century_start + 100]\n",
    "    if century_data:\n",
    "        total_gs = sum(d[\"global_south\"] for d in century_data)\n",
    "        total_all = sum(d[\"total\"] for d in century_data)\n",
    "        pct = (total_gs / total_all) * 100 if total_all > 0 else 0\n",
    "        print(f\"[{timestamp()}]   {century_start}s: {pct:.1f}% ({total_gs:,} of {total_all:,})\")\n",
    "\n",
    "# Create Vega-Lite spec\n",
    "geo_timeline_spec = {\n",
    "    \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n",
    "    \"data\": {\"values\": geo_timeline_data},\n",
    "    \"transform\": [\n",
    "        {\"filter\": \"datum.decade < 1980\"}\n",
    "    ],\n",
    "    \"mark\": {\n",
    "        \"type\": \"line\",\n",
    "        \"color\": \"#FF00D3\",\n",
    "        \"strokeWidth\": 2,\n",
    "        \"interpolate\": \"monotone\"\n",
    "    },\n",
    "    \"encoding\": {\n",
    "        \"x\": {\n",
    "        \"field\": \"decade\",\n",
    "            \"type\": \"quantitative\",\n",
    "            \"title\": \"\",\n",
    "            \"scale\": {\"domain\": [1500, 2000]},\n",
    "            \"axis\": {\"format\": \"d\", \"tickCount\": 6},\n",
    "        },\n",
    "        \"y\": {\n",
    "            \"field\": \"percentage\",\n",
    "            \"type\": \"quantitative\",\n",
    "            \"title\": \"\",\n",
    "            \"axis\": {\"format\": \".0f\"},\n",
    "            \"scale\": {\"domain\": [0, 20]}\n",
    "        },\n",
    "        \"tooltip\": [\n",
    "            {\"field\": \"decade\", \"type\": \"ordinal\", \"title\": \"Decade\"},\n",
    "            {\"field\": \"percentage\", \"type\": \"quantitative\", \"title\": \"% Global South\", \"format\": \".1f\"},\n",
    "            {\"field\": \"global_south\", \"type\": \"quantitative\", \"title\": \"Non-Western painters\", \"format\": \",\"},\n",
    "            {\"field\": \"total\", \"type\": \"quantitative\", \"title\": \"Total painters\", \"format\": \",\"}\n",
    "        ]\n",
    "    },\n",
    "    \"width\": 400,\n",
    "    \"height\": 300\n",
    "}\n",
    "\n",
    "output_path = os.path.join(VIS_DIR, \"geo_timeline.json\")\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(geo_timeline_spec, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"[{timestamp()}] Output: {output_path}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Summary statistics\n",
    "# ---------------------------------------------------------------------------\n",
    "print(f\"\\n[{timestamp()}] {'='*50}\")\n",
    "print(f\"[{timestamp()}] GLOBAL SOUTH TIMELINE SUMMARY\")\n",
    "print(f\"[{timestamp()}] {'='*50}\")\n",
    "\n",
    "if geo_timeline_data:\n",
    "    earliest = min(geo_timeline_data, key=lambda x: x[\"decade\"])\n",
    "    latest = [d for d in geo_timeline_data if d[\"decade\"] <= 1980][-1]\n",
    "    peak = max(geo_timeline_data, key=lambda x: x[\"percentage\"])\n",
    "    \n",
    "    print(f\"[{timestamp()}] Earliest decade: {earliest['decade']}s ({earliest['percentage']:.1f}% Global South)\")\n",
    "    print(f\"[{timestamp()}] Latest decade: {latest['decade']}s ({latest['percentage']:.1f}% Global South)\")\n",
    "    print(f\"[{timestamp()}] Peak: {peak['decade']}s ({peak['percentage']:.1f}% Global South)\")\n",
    "print(f\"[{timestamp()}] {'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GENDER VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n[{timestamp()}] Creating gender chart...\")\n",
    "\n",
    "gender_data = []\n",
    "for qid, count in gender_counts.most_common():\n",
    "    label = get_label(qid).title()\n",
    "    gender_data.append({\"gender\": label, \"count\": count})\n",
    "\n",
    "# Collapse small categories\n",
    "processed_data = []\n",
    "other_total = 0\n",
    "for entry in gender_data:\n",
    "    if entry[\"count\"] <= 1000:\n",
    "        other_total += entry[\"count\"]\n",
    "    else:\n",
    "        processed_data.append(entry)\n",
    "\n",
    "if other_total > 0:\n",
    "    processed_data.append({\"gender\": \"Other\", \"count\": other_total})\n",
    "\n",
    "processed_data = sorted(processed_data, key=lambda x: x[\"count\"], reverse=True)\n",
    "\n",
    "gender_domain = [\"Female\", \"Male\"]\n",
    "color_map = {\n",
    "    \"Female\": \"#FF00D3\",\n",
    "    \"Male\": \"#CCCCCC\",\n",
    "}\n",
    "gender_range = [color_map.get(g, \"#999999\") for g in gender_domain]\n",
    "\n",
    "# Create pie chart spec\n",
    "gender_spec = {\n",
    "    \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n",
    "    \"data\": {\"values\": processed_data},\n",
    "    \"mark\": {\"type\": \"arc\", \"innerRadius\": 75},\n",
    "    \"encoding\": {\n",
    "        \"theta\": {\"field\": \"count\", \"type\": \"quantitative\"},\n",
    "        \"color\": {\n",
    "            \"field\": \"gender\",\n",
    "            \"type\": \"nominal\",\n",
    "            \"legend\": {\"title\": \"Gender\"},\n",
    "            \"scale\": {\n",
    "                \"domain\": gender_domain,\n",
    "                \"range\": gender_range\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "    \"width\": 300,\n",
    "    \"height\": 300\n",
    "}\n",
    "\n",
    "output_path = os.path.join(VIS_DIR, \"gender.json\")\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(gender_spec, f, ensure_ascii=False, indent=2)\n",
    "print(f\"[{timestamp()}] Output: {output_path}\")\n",
    "\n",
    "print(f\"\\n[{timestamp()}] GENDER SUMMARY\")\n",
    "for d in processed_data:\n",
    "    print(f\"  {d['gender']}: {d['count']:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# INCEPTION TIMELINE (Paintings by decade)\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n[{timestamp()}] Creating inception timeline...\")\n",
    "\n",
    "decade_data = []\n",
    "for decade in sorted(decade_counts.keys()):\n",
    "    decade_data.append({\"decade\": f\"{decade}-01-01\", \"count\": decade_counts[decade]})\n",
    "\n",
    "inception_spec = {\n",
    "    \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n",
    "    \"data\": {\"values\": decade_data},\n",
    "    \"mark\": {\n",
    "        \"type\": \"line\",\n",
    "        \"color\": \"#000000\",\n",
    "        \"strokeWidth\": 2,        \n",
    "    },\n",
    "    \"encoding\": {\n",
    "        \"x\": {\n",
    "            \"field\": \"decade\",\n",
    "            \"type\": \"temporal\",\n",
    "            \"title\": \"\",\n",
    "            \"axis\": {\"tickCount\": 7}\n",
    "        },\n",
    "        \"y\": {\n",
    "            \"field\": \"count\",\n",
    "            \"type\": \"quantitative\",\n",
    "            \"title\": \"\"\n",
    "        }\n",
    "    },\n",
    "    \"width\": 300,\n",
    "    \"height\": 300\n",
    "}\n",
    "\n",
    "output_path = os.path.join(VIS_DIR, \"inception.json\")\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(inception_spec, f, ensure_ascii=False, indent=2)\n",
    "print(f\"[{timestamp()}] Output: {output_path}\")\n",
    "\n",
    "print(f\"\\n[{timestamp()}] INCEPTION SUMMARY\")\n",
    "print(f\"[{timestamp()}] Total paintings: {len(painting_qids):,}\")\n",
    "print(f\"[{timestamp()}] With inception date: {len(paintings_with_year):,} ({100*len(paintings_with_year)/len(painting_qids):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MOVEMENTS TIMELINES (One per major movement)\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n[{timestamp()}] Creating movement timelines...\")\n",
    "\n",
    "# Define the 6 movements to include\n",
    "TIMELINE_MOVEMENTS = [\"Baroque\", \"Impressionism\", \"Expressionism\", \"Realism\", \"Symbolism\", \"Romanticism\"]\n",
    "\n",
    "# Build QID -> label mapping for top movements\n",
    "movement_qid_to_label = {}\n",
    "for qid, count in movement_counts_with_inheritance.most_common(100):\n",
    "    label = get_label(qid)\n",
    "    clean_label = clean_movement_label(label)\n",
    "    movement_qid_to_label[qid] = clean_label\n",
    "\n",
    "# Get QIDs for our target movements\n",
    "target_movement_qids = set()\n",
    "for qid, label in movement_qid_to_label.items():\n",
    "    if label in TIMELINE_MOVEMENTS:\n",
    "        target_movement_qids.add(qid)\n",
    "\n",
    "# Aggregate by decade for target movements\n",
    "movement_decade_counts = defaultdict(Counter)\n",
    "\n",
    "for year, movement_qid in painting_year_movement_inherited:\n",
    "    if movement_qid in target_movement_qids:\n",
    "        decade = (year // 10) * 10\n",
    "        label = movement_qid_to_label[movement_qid]\n",
    "        movement_decade_counts[label][decade] += 1\n",
    "\n",
    "# Build timeline data for all movements\n",
    "all_decades = set()\n",
    "for counts in movement_decade_counts.values():\n",
    "    all_decades.update(counts.keys())\n",
    "all_decades = sorted(all_decades)\n",
    "\n",
    "timeline_data = []\n",
    "for decade in all_decades:\n",
    "    for movement in TIMELINE_MOVEMENTS:\n",
    "        count = movement_decade_counts[movement].get(decade, 0)\n",
    "        timeline_data.append({\n",
    "            \"decade\": decade,\n",
    "            \"count\": count,\n",
    "            \"movement\": movement\n",
    "        })\n",
    "\n",
    "def create_movement_timeline_spec(highlight_movement, data, movements):\n",
    "    \"\"\"Create a spec with one movement highlighted and others gray.\"\"\"\n",
    "    \n",
    "    color_range = [\"#FF00D3\" if m == highlight_movement else \"rgba(119, 119, 119, 0.5)\" for m in movements]\n",
    "    filtered_timeline_data = [d for d in timeline_data if 1500 <= d['decade'] <= 2000]\n",
    "    return {\n",
    "        \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n",
    "        \"data\": {\"values\": filtered_timeline_data},\n",
    "        \"mark\": {\n",
    "            \"type\": \"line\",\n",
    "            \"interpolate\": \"monotone\",                \n",
    "        },\n",
    "        \"encoding\": {\n",
    "            \"x\": {\n",
    "                \"field\": \"decade\",\n",
    "                \"type\": \"quantitative\",\n",
    "                \"title\": \"\",\n",
    "                \"axis\": {\"format\": \"d\", \"tickCount\": 10},\n",
    "                \"scale\": {\"domain\": [1500, 2000]}\n",
    "            },\n",
    "            \"y\": {\n",
    "                \"field\": \"count\",\n",
    "                \"type\": \"quantitative\",\n",
    "                \"title\": \"\",\n",
    "                \"axis\": {\"format\": \"d\", \"tickCount\": 10},\n",
    "            },\n",
    "            \"color\": {\n",
    "                \"field\": \"movement\",\n",
    "                \"type\": \"nominal\",\n",
    "                \"title\": \"Movement\",\n",
    "                \"scale\": {\n",
    "                    \"domain\": movements,\n",
    "                    \"range\": color_range\n",
    "                },\n",
    "                \"legend\": None\n",
    "            },\n",
    "            \"strokeWidth\": {\n",
    "                \"condition\": {\n",
    "                    \"test\": f\"datum.movement === '{highlight_movement}'\",\n",
    "                    \"value\": 2\n",
    "                },\n",
    "                \"value\": 1.5\n",
    "            }\n",
    "        },\n",
    "        \"width\": 400,\n",
    "        \"height\": 300\n",
    "    }\n",
    "\n",
    "# Create a spec for each movement\n",
    "for movement in TIMELINE_MOVEMENTS:\n",
    "    spec = create_movement_timeline_spec(movement, timeline_data, TIMELINE_MOVEMENTS)\n",
    "    \n",
    "    filename = f\"movements_timeline_{movement.lower()}.json\"\n",
    "    output_path = os.path.join(VIS_DIR, filename)\n",
    "    \n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(spec, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"[{timestamp()}] Output: {output_path}\")\n",
    "\n",
    "print(f\"[{timestamp()}] Created {len(TIMELINE_MOVEMENTS)} movement timeline specs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GENRE TIMELINES (Portrait, Religious, Landscape)\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n[{timestamp()}] Creating genre timelines...\")\n",
    "\n",
    "# Get all decades from genre data\n",
    "all_genre_decades = set()\n",
    "for counts in genre_decade_counts.values():\n",
    "    all_genre_decades.update(counts.keys())\n",
    "all_genre_decades = sorted(all_genre_decades)\n",
    "\n",
    "# Build timeline data for all genres\n",
    "genre_timeline_data = []\n",
    "for decade in all_genre_decades:\n",
    "    for genre_name in TIMELINE_GENRES.values():\n",
    "        count = genre_decade_counts[genre_name].get(decade, 0)\n",
    "        genre_timeline_data.append({\n",
    "            \"decade\": f\"{decade}-01-01\",\n",
    "            \"count\": count,\n",
    "            \"genre\": genre_name\n",
    "        })\n",
    "\n",
    "def create_genre_timeline_spec(highlight_genre, all_data, genres):\n",
    "    \"\"\"Create a spec with one genre highlighted and others gray.\"\"\"\n",
    "    \n",
    "    color_map = {\n",
    "        \"portrait\": \"#FF00D3\",\n",
    "        \"religious\": \"#FF00D3\", \n",
    "        \"landscape\": \"#FF00D3\"\n",
    "    }\n",
    "    \n",
    "    domain = list(genres)\n",
    "    range_colors = []\n",
    "    for g in domain:\n",
    "        if g == highlight_genre:\n",
    "            range_colors.append(color_map[g])\n",
    "        else:\n",
    "            range_colors.append(\"rgba(119, 119, 119)\")\n",
    "    \n",
    "    return {\n",
    "        \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n",
    "        \"data\": {\"values\": all_data},\n",
    "        \"mark\": {\n",
    "            \"type\": \"line\",\n",
    "            \"strokeWidth\": 2,\n",
    "            \"clip\": True,\n",
    "            \"interpolate\": \"monotone\"\n",
    "        },\n",
    "        \"encoding\": {\n",
    "            \"x\": {\n",
    "                \"field\": \"decade\",\n",
    "                \"type\": \"temporal\",\n",
    "                \"title\": \"\",\n",
    "                \"scale\": {\"domain\": [\"1201\", \"2000\"]}\n",
    "            },\n",
    "            \"y\": {\n",
    "                \"field\": \"count\",\n",
    "                \"type\": \"quantitative\",\n",
    "                \"title\": \"\"\n",
    "            },\n",
    "            \"color\": {\n",
    "                \"field\": \"genre\",\n",
    "                \"type\": \"nominal\",\n",
    "                \"legend\": None,\n",
    "                \"scale\": {\n",
    "                    \"domain\": domain,\n",
    "                    \"range\": range_colors\n",
    "                }\n",
    "            },\n",
    "            \"opacity\": {\n",
    "                \"condition\": {\n",
    "                    \"test\": f\"datum.genre === '{highlight_genre}'\",\n",
    "                    \"value\": 1\n",
    "                },\n",
    "                \"value\": 0.3\n",
    "            },\n",
    "            \"order\": {\n",
    "                \"condition\": {\n",
    "                    \"test\": f\"datum.genre === '{highlight_genre}'\",\n",
    "                    \"value\": 1\n",
    "                },\n",
    "                \"value\": 0\n",
    "            }\n",
    "        },\n",
    "        \"width\": 300,\n",
    "        \"height\": 200\n",
    "    }\n",
    "\n",
    "# Create specs for each genre\n",
    "for genre_name in TIMELINE_GENRES.values():\n",
    "    spec = create_genre_timeline_spec(genre_name, genre_timeline_data, TIMELINE_GENRES.values())\n",
    "    \n",
    "    output_path = os.path.join(VIS_DIR, f\"genre_timeline_{genre_name}.json\")\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(spec, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"[{timestamp()}] Output: {output_path}\")\n",
    "\n",
    "print(f\"\\n[{timestamp()}] GENRE TIMELINE SUMMARY\")\n",
    "for genre_name, counts in genre_decade_counts.items():\n",
    "    peak_decade = max(counts, key=counts.get) if counts else \"N/A\"\n",
    "    peak_count = counts[peak_decade] if counts else 0\n",
    "    print(f\"[{timestamp()}] {genre_name.capitalize()}:\")\n",
    "    print(f\"[{timestamp()}]   Total: {sum(counts.values()):,}\")\n",
    "    print(f\"[{timestamp()}]   Peak: {peak_decade}s ({peak_count:,} paintings)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ARTIST PRODUCTIVITY VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n[{timestamp()}] Creating productivity visualization...\")\n",
    "\n",
    "# Filter for artists with at least 100 works in dataset\n",
    "artists_with_works = [a for a in artist_data if a[\"works_in_dataset\"] >= 100]\n",
    "print(f\"[{timestamp()}] Artists with 100+ works: {len(artists_with_works):,}\")\n",
    "\n",
    "# Add labels\n",
    "for a in artists_with_works:\n",
    "    a[\"label\"] = get_label(a[\"qid\"])\n",
    "    a[\"works_per_year\"] = a[\"works_in_dataset\"] / a[\"lifespan\"]\n",
    "\n",
    "# Create scatterplot\n",
    "productivity_data = [\n",
    "    {\"lifespan\": a[\"lifespan\"], \"works\": a[\"works_in_dataset\"], \"label\": a[\"label\"]}\n",
    "    for a in artists_with_works\n",
    "]\n",
    "\n",
    "productivity_spec = {\n",
    "    \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n",
    "    \"data\": {\"values\": productivity_data},\n",
    "    \"mark\": {\"type\": \"circle\", \"opacity\": 0.5, \"color\": \"#000000\", \"size\": 10},\n",
    "    \"encoding\": {\n",
    "        \"x\": {\n",
    "            \"field\": \"lifespan\",\n",
    "            \"type\": \"quantitative\",\n",
    "            \"title\": \"Lifespan (years)\",\n",
    "            \"scale\": {\"domain\": [20, 105]}\n",
    "        },\n",
    "        \"y\": {\n",
    "            \"field\": \"works\",\n",
    "            \"type\": \"quantitative\",\n",
    "            \"title\": \"Paintings in dataset\",\n",
    "            \"scale\": {\"domain\": [0, 4000]}\n",
    "        },\n",
    "        \"tooltip\": [\n",
    "            {\"field\": \"label\", \"type\": \"nominal\", \"title\": \"Artist\"},\n",
    "            {\"field\": \"lifespan\", \"type\": \"quantitative\", \"title\": \"Lifespan\"},\n",
    "            {\"field\": \"works\", \"type\": \"quantitative\", \"title\": \"Paintings\"}\n",
    "        ]\n",
    "    },\n",
    "    \"width\": 400,\n",
    "    \"height\": 300\n",
    "}\n",
    "\n",
    "output_path = os.path.join(VIS_DIR, \"productivity.json\")\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(productivity_spec, f, ensure_ascii=False, indent=2)\n",
    "print(f\"[{timestamp()}] Output: {output_path}\")\n",
    "\n",
    "# Print outliers\n",
    "if artists_with_works:\n",
    "    youngest = min(artists_with_works, key=lambda a: a[\"lifespan\"])\n",
    "    oldest = max(artists_with_works, key=lambda a: a[\"lifespan\"])\n",
    "    most_works = max(artists_with_works, key=lambda a: a[\"works_in_dataset\"])\n",
    "    most_productive = max(artists_with_works, key=lambda a: a[\"works_per_year\"])\n",
    "    \n",
    "    print(f\"\\n[{timestamp()}] OUTLIERS:\")\n",
    "    print(f\"  Shortest lifespan: {youngest['label']} ({youngest['lifespan']:.1f} years, {youngest['works_in_dataset']} works)\")\n",
    "    print(f\"  Longest lifespan: {oldest['label']} ({oldest['lifespan']:.1f} years, {oldest['works_in_dataset']} works)\")\n",
    "    print(f\"  Most works: {most_works['label']} ({most_works['works_in_dataset']} works)\")\n",
    "    print(f\"  Most productive: {most_productive['label']} ({most_productive['works_per_year']:.2f} works/year)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEMALE PAINTER RATIO BY BIRTH DECADE\n",
    "# =============================================================================\n",
    "print(f\"\\n[{timestamp()}] Calculating female painter ratio by birth decade...\")\n",
    "\n",
    "# Define female gender QIDs\n",
    "FEMALE_QIDS = {\"Q6581072\", \"Q1052281\"}  # female, transgender female\n",
    "\n",
    "# Count total and female artists per birth decade\n",
    "birth_decade_total = Counter()\n",
    "birth_decade_female = Counter()\n",
    "\n",
    "for creator_qid in all_creator_qids:\n",
    "    entity = creator_entities.get(creator_qid)\n",
    "    if entity is None:\n",
    "        continue\n",
    "    \n",
    "    # Get birth date\n",
    "    birth_dates = get_claim_time_values(entity, \"P569\")\n",
    "    if not birth_dates:\n",
    "        continue\n",
    "    \n",
    "    birth_date = parse_date(birth_dates[0])\n",
    "    if birth_date is None:\n",
    "        continue\n",
    "    \n",
    "    birth_year = birth_date[0]\n",
    "    if birth_year < 1500 or birth_year > 2000:\n",
    "        continue\n",
    "    \n",
    "    decade = (birth_year // 10) * 10\n",
    "    birth_decade_total[decade] += 1\n",
    "    \n",
    "    # Check gender\n",
    "    genders = get_claim_values(entity, \"P21\")\n",
    "    if any(g in FEMALE_QIDS for g in genders):\n",
    "        birth_decade_female[decade] += 1\n",
    "\n",
    "# Build timeline data\n",
    "gender_timeline_data = []\n",
    "for decade in sorted(birth_decade_total.keys()):\n",
    "    total = birth_decade_total[decade]\n",
    "    female = birth_decade_female.get(decade, 0)\n",
    "    \n",
    "    if total >= 1:\n",
    "        pct = (female / total) * 100\n",
    "        gender_timeline_data.append({\n",
    "            \"decade\": decade,\n",
    "            \"percentage\": round(pct, 2),\n",
    "            \"female\": female,\n",
    "            \"total\": total\n",
    "        })\n",
    "\n",
    "print(f\"[{timestamp()}] Decades with data: {len(gender_timeline_data)}\")\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\n[{timestamp()}] Female painter percentage by century:\")\n",
    "for century_start in range(1500, 2000, 100):\n",
    "    century_data = [d for d in gender_timeline_data if century_start <= d[\"decade\"] < century_start + 100]\n",
    "    if century_data:\n",
    "        total_female = sum(d[\"female\"] for d in century_data)\n",
    "        total_all = sum(d[\"total\"] for d in century_data)\n",
    "        pct = (total_female / total_all) * 100 if total_all > 0 else 0\n",
    "        print(f\"[{timestamp()}]   {century_start}s: {pct:.1f}% ({total_female:,} of {total_all:,})\")\n",
    "\n",
    "# Create Vega-Lite bar chart spec\n",
    "gender_timeline_spec = {\n",
    "    \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n",
    "    \"data\": {\"values\": gender_timeline_data},\n",
    "    \"transform\": [ {\"filter\": \"datum.decade < 2000\"} ],\n",
    "    \"mark\": {\n",
    "        \"type\": \"line\",\n",
    "        \"color\": \"#8700F9\",\n",
    "        \"interpolate\": \"monotone\",                \n",
    "    },\n",
    "    \"encoding\": {\n",
    "        \"x\": {\n",
    "            \"field\": \"decade\",\n",
    "            \"type\": \"quantitative\",\n",
    "            \"title\": \"\",\n",
    "            \"scale\": {\"domain\": [1500, 2000]},\n",
    "            \"axis\": {\"format\": \"d\", \"tickCount\": 6},\n",
    "        },\n",
    "        \"y\": {\n",
    "            \"field\": \"percentage\",\n",
    "            \"type\": \"quantitative\",\n",
    "            \"title\": \"\",\n",
    "            \"axis\": {\"format\": \".0f\"},\n",
    "            \"scale\": {\"domain\": [0, 50]}\n",
    "        },\n",
    "        \"tooltip\": [\n",
    "            {\"field\": \"decade\", \"type\": \"ordinal\", \"title\": \"Decade\"},\n",
    "            {\"field\": \"percentage\", \"type\": \"quantitative\", \"title\": \"% Female\", \"format\": \".1f\"},\n",
    "            {\"field\": \"female\", \"type\": \"quantitative\", \"title\": \"Female painters\", \"format\": \",\"},\n",
    "            {\"field\": \"total\", \"type\": \"quantitative\", \"title\": \"Total painters\", \"format\": \",\"}\n",
    "        ]\n",
    "    },\n",
    "    \"width\": 400,\n",
    "    \"height\": 300\n",
    "}\n",
    "\n",
    "output_path = os.path.join(VIS_DIR, \"gender_timeline.json\")\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(gender_timeline_spec, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"[{timestamp()}] Output: {output_path}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Summary statistics\n",
    "# ---------------------------------------------------------------------------\n",
    "print(f\"\\n[{timestamp()}] {'='*50}\")\n",
    "print(f\"[{timestamp()}] GENDER TIMELINE SUMMARY\")\n",
    "print(f\"[{timestamp()}] {'='*50}\")\n",
    "\n",
    "if gender_timeline_data:\n",
    "    earliest = min(gender_timeline_data, key=lambda x: x[\"decade\"])\n",
    "    latest = max(gender_timeline_data, key=lambda x: x[\"decade\"])\n",
    "    peak = max(gender_timeline_data, key=lambda x: x[\"percentage\"])\n",
    "    \n",
    "    print(f\"[{timestamp()}] Earliest decade: {earliest['decade']}s ({earliest['percentage']:.1f}% female)\")\n",
    "    print(f\"[{timestamp()}] Latest decade: {latest['decade']}s ({latest['percentage']:.1f}% female)\")\n",
    "    print(f\"[{timestamp()}] Peak: {peak['decade']}s ({peak['percentage']:.1f}% female)\")\n",
    "print(f\"[{timestamp()}] {'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ARTIST SITELINKS VS PAINTINGS SCATTERPLOT\n",
    "# =============================================================================\n",
    "print(f\"\\n[{timestamp()}] Analyzing artist sitelinks vs paintings...\")\n",
    "\n",
    "PAINTER_QID = \"Q1028181\"  # painter occupation\n",
    "\n",
    "# Exclude entities that aren't primarily artists\n",
    "EXCLUDE_QIDS = {\n",
    "    \"Q302\",      # Jesus Christ\n",
    "    \"Q352\",      # Adolf Hitler\n",
    "    \"Q8016\",     # Winston Churchill\n",
    "    \"Q5879\",     # Walt Disney\n",
    "    \"Q7243\",     # Le Corbusier (primarily architect)\n",
    "    \"Q529\",      # Louis Pasteur\n",
    "    \"Q7241\",     # Rabindranath Tagore (primarily writer)\n",
    "}\n",
    "\n",
    "sitelink_data = []\n",
    "non_painters_skipped = 0\n",
    "excluded_skipped = 0\n",
    "\n",
    "for creator_qid in all_creator_qids:\n",
    "    if creator_qid in EXCLUDE_QIDS:\n",
    "        excluded_skipped += 1\n",
    "        continue\n",
    "    \n",
    "    entity = creator_entities.get(creator_qid)\n",
    "    if entity is None:\n",
    "        continue\n",
    "    \n",
    "    # Check if occupation includes painter\n",
    "    occupations = get_claim_values(entity, \"P106\")\n",
    "    if PAINTER_QID not in occupations:\n",
    "        non_painters_skipped += 1\n",
    "        continue\n",
    "    \n",
    "    sitelinks = entity.get(\"sitelinks\", {})\n",
    "    # Count only Wikipedia links\n",
    "    wiki_count = sum(1 for key in sitelinks.keys() if key.endswith(\"wiki\") and not key.endswith((\"wikiquote\", \"wikisource\", \"wikivoyage\", \"wikinews\", \"wikiversity\", \"wikibooks\")))\n",
    "    \n",
    "    paintings = creator_painting_count.get(creator_qid, 0)\n",
    "    \n",
    "    sitelink_data.append({\n",
    "        \"qid\": creator_qid,\n",
    "        \"sitelinks\": wiki_count,\n",
    "        \"paintings\": paintings\n",
    "    })\n",
    "\n",
    "print(f\"[{timestamp()}] Painters found: {len(sitelink_data):,}\")\n",
    "print(f\"[{timestamp()}] Non-painters skipped: {non_painters_skipped:,}\")\n",
    "print(f\"[{timestamp()}] Excluded manually: {excluded_skipped:,}\")\n",
    "\n",
    "# Add labels for chart\n",
    "for item in sitelink_data:\n",
    "    item[\"label\"] = get_label(item[\"qid\"])\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Scatterplot: Sitelinks (x) vs Paintings (y)\n",
    "# ---------------------------------------------------------------------------\n",
    "scatter_data = [\n",
    "    {\"sitelinks\": d[\"sitelinks\"], \"paintings\": d[\"paintings\"], \"label\": d[\"label\"]}\n",
    "    for d in sitelink_data\n",
    "]\n",
    "\n",
    "sitelinks_scatter_spec = {\n",
    "    \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n",
    "    \"data\": {\"values\": scatter_data},\n",
    "    \"mark\": {\"type\": \"circle\", \"opacity\": 0.6, \"color\": \"#000000\", \"size\": 10},\n",
    "    \"encoding\": {\n",
    "        \"x\": {\n",
    "            \"field\": \"sitelinks\",\n",
    "            \"type\": \"quantitative\",\n",
    "            \"title\": \"\",\n",
    "            \"scale\": {\"domain\": [0, 250]}\n",
    "        },\n",
    "        \"y\": {\n",
    "            \"field\": \"paintings\",\n",
    "            \"type\": \"quantitative\",\n",
    "            \"title\": \"\",\n",
    "            \"scale\": {\"domain\": [0, 4000]}\n",
    "        },\n",
    "        \"tooltip\": [\n",
    "            {\"field\": \"label\", \"type\": \"nominal\", \"title\": \"Artist\"},\n",
    "            {\"field\": \"sitelinks\", \"type\": \"quantitative\", \"title\": \"Wikipedias\"},\n",
    "            {\"field\": \"paintings\", \"type\": \"quantitative\", \"title\": \"Paintings\"}\n",
    "        ]\n",
    "    },\n",
    "    \"width\": 400,\n",
    "    \"height\": 300\n",
    "}\n",
    "\n",
    "output_path = os.path.join(VIS_DIR, \"sitelinks_paintings.json\")\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sitelinks_scatter_spec, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"[{timestamp()}] Output: {output_path}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Interesting outliers\n",
    "# ---------------------------------------------------------------------------\n",
    "print(f\"\\n[{timestamp()}] OUTLIERS:\")\n",
    "\n",
    "# Famous but few works (high sitelinks, low paintings)\n",
    "famous_few_works = [d for d in sitelink_data if d[\"sitelinks\"] >= 50 and d[\"paintings\"] <= 20]\n",
    "famous_few_works = sorted(famous_few_works, key=lambda x: x[\"sitelinks\"], reverse=True)[:10]\n",
    "print(f\"\\n[{timestamp()}] Famous but few works (50+ Wikipedias, â¤20 paintings):\")\n",
    "for d in famous_few_works:\n",
    "    print(f\"[{timestamp()}]   {d['label']}: {d['sitelinks']} Wikipedias, {d['paintings']} paintings\")\n",
    "\n",
    "# Prolific but obscure (many paintings, few sitelinks)\n",
    "prolific_obscure = [d for d in sitelink_data if d[\"paintings\"] >= 100 and d[\"sitelinks\"] <= 10]\n",
    "prolific_obscure = sorted(prolific_obscure, key=lambda x: x[\"paintings\"], reverse=True)[:10]\n",
    "print(f\"\\n[{timestamp()}] Prolific but obscure (100+ paintings, â¤10 Wikipedias):\")\n",
    "for d in prolific_obscure:\n",
    "    print(f\"[{timestamp()}]   {d['label']}: {d['paintings']} paintings, {d['sitelinks']} Wikipedias\")\n",
    "\n",
    "# Most famous painters\n",
    "most_famous = sorted(sitelink_data, key=lambda x: x[\"sitelinks\"], reverse=True)[:10]\n",
    "print(f\"\\n[{timestamp()}] Most famous painters:\")\n",
    "for d in most_famous:\n",
    "    print(f\"[{timestamp()}]   {d['label']}: {d['sitelinks']} Wikipedias, {d['paintings']} paintings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FINAL SUMMARY\n",
    "# =============================================================================\n",
    "print(f\"\\n[{timestamp()}] {'='*60}\")\n",
    "print(f\"[{timestamp()}] PROCESSING COMPLETE\")\n",
    "print(f\"[{timestamp()}] {'='*60}\")\n",
    "print(f\"[{timestamp()}] Total paintings: {len(painting_qids):,}\")\n",
    "print(f\"[{timestamp()}] Total creators: {len(all_creator_qids):,}\")\n",
    "print(f\"[{timestamp()}]\")\n",
    "print(f\"[{timestamp()}] Paintings with:\")\n",
    "print(f\"[{timestamp()}]   Movement: {len(paintings_with_movement_inherited):,} ({100*len(paintings_with_movement_inherited)/len(painting_qids):.1f}%)\")\n",
    "print(f\"[{timestamp()}]   Material: {len(paintings_with_material):,} ({100*len(paintings_with_material)/len(painting_qids):.1f}%)\")\n",
    "print(f\"[{timestamp()}]   Genre: {len(paintings_with_genre):,} ({100*len(paintings_with_genre)/len(painting_qids):.1f}%)\")\n",
    "print(f\"[{timestamp()}]   Collection: {len(paintings_with_collection):,} ({100*len(paintings_with_collection)/len(painting_qids):.1f}%)\")\n",
    "print(f\"[{timestamp()}]   Year: {len(paintings_with_year):,} ({100*len(paintings_with_year)/len(painting_qids):.1f}%)\")\n",
    "print(f\"[{timestamp()}]\")\n",
    "print(f\"[{timestamp()}] Creators with:\")\n",
    "print(f\"[{timestamp()}]   Gender: {creators_with_gender:,}\")\n",
    "print(f\"[{timestamp()}]   Birthplace: {creators_with_birthplace:,}\")\n",
    "print(f\"[{timestamp()}]   Country: {creators_with_country:,}\")\n",
    "print(f\"[{timestamp()}]   Lifespan data: {len(artist_data):,}\")\n",
    "print(f\"[{timestamp()}]\")\n",
    "print(f\"[{timestamp()}] Gender timeline:\")\n",
    "total_female = sum(d[\"female\"] for d in gender_timeline_data)\n",
    "total_in_timeline = sum(d[\"total\"] for d in gender_timeline_data)\n",
    "print(f\"[{timestamp()}]   Painters in timeline: {total_in_timeline:,}\")\n",
    "print(f\"[{timestamp()}]   Female painters: {total_female:,} ({100*total_female/total_in_timeline:.1f}%)\")\n",
    "if gender_timeline_data:\n",
    "    earliest = min(gender_timeline_data, key=lambda x: x[\"decade\"])\n",
    "    latest = max(gender_timeline_data, key=lambda x: x[\"decade\"])\n",
    "    peak = max(gender_timeline_data, key=lambda x: x[\"percentage\"])\n",
    "    print(f\"[{timestamp()}]   Earliest: {earliest['decade']}s ({earliest['percentage']:.1f}% female)\")\n",
    "    print(f\"[{timestamp()}]   Latest: {latest['decade']}s ({latest['percentage']:.1f}% female)\")\n",
    "    print(f\"[{timestamp()}]   Peak: {peak['decade']}s ({peak['percentage']:.1f}% female)\")\n",
    "print(f\"[{timestamp()}]\")\n",
    "print(f\"[{timestamp()}] Output files generated:\")\n",
    "print(f\"[{timestamp()}]   - movements.json\")\n",
    "print(f\"[{timestamp()}]   - movements_timeline_*.json (6 files)\")\n",
    "print(f\"[{timestamp()}]   - materials.json\")\n",
    "print(f\"[{timestamp()}]   - genre.json\")\n",
    "print(f\"[{timestamp()}]   - genre_timeline_*.json (3 files)\")\n",
    "print(f\"[{timestamp()}]   - collection.json\")\n",
    "print(f\"[{timestamp()}]   - gender.json\")\n",
    "print(f\"[{timestamp()}]   - gender_timeline.json\")\n",
    "print(f\"[{timestamp()}]   - country.json\")\n",
    "print(f\"[{timestamp()}]   - continent.json\")\n",
    "print(f\"[{timestamp()}]   - inception.json\")\n",
    "print(f\"[{timestamp()}]   - productivity.json\")\n",
    "print(f\"[{timestamp()}] {'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COVERAGE / DATA GAPS VISUALIZATION\n",
    "# =============================================================================\n",
    "print(f\"\\n[{timestamp()}] Creating coverage chart...\")\n",
    "\n",
    "total = len(painting_qids)\n",
    "\n",
    "coverage_data = [\n",
    "    {\"property\": \"Inception\", \"percentage\": round(100 * len(paintings_with_year) / total, 1)},\n",
    "    {\"property\": \"Creator\", \"percentage\": round(100 * len(paintings_with_creator) / total, 1)},\n",
    "    {\"property\": \"Material\", \"percentage\": round(100 * len(paintings_with_material) / total, 1)},\n",
    "    {\"property\": \"Genre\", \"percentage\": round(100 * len(paintings_with_genre) / total, 1)},\n",
    "    {\"property\": \"Movement\", \"percentage\": round(100 * len(paintings_with_movement_inherited) / total, 1)},\n",
    "]\n",
    "\n",
    "# Sort by coverage\n",
    "coverage_data = sorted(coverage_data, key=lambda x: x[\"percentage\"], reverse=True)\n",
    "\n",
    "for d in coverage_data:\n",
    "    print(f\"[{timestamp()}]   {d['property']}: {d['percentage']}%\")\n",
    "\n",
    "coverage_spec = {\n",
    "    \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n",
    "    \"data\": {\"values\": coverage_data},\n",
    "    \"mark\": {\"type\": \"bar\", \"color\": \"#999999\", \"height\": 20},\n",
    "    \"encoding\": {\n",
    "        \"y\": {\n",
    "            \"field\": \"property\",\n",
    "            \"type\": \"nominal\",\n",
    "            \"sort\": [d[\"property\"] for d in coverage_data],\n",
    "            \"title\": \"\"\n",
    "        },\n",
    "        \"x\": {\n",
    "            \"field\": \"percentage\",\n",
    "            \"type\": \"quantitative\",\n",
    "            \"title\": \"\",\n",
    "            \"scale\": {\"domain\": [0, 100]},\n",
    "            \"axis\": {\"format\": \".0f\"}\n",
    "        }\n",
    "    },\n",
    "    \"width\": 300,\n",
    "    \"height\": 200\n",
    "}\n",
    "\n",
    "output_path = os.path.join(VIS_DIR, \"coverage.json\")\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(coverage_spec, f, ensure_ascii=False, indent=2)\n",
    "print(f\"[{timestamp()}] Output: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
